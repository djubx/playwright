<-- START_DESCRIPTION -->
# vosk_flutter_2 Package Overview
=====================================

The vosk_flutter_2 package is a Flutter wrapper for the Vosk speech recognition library. It allows developers to integrate speech recognition capabilities into their Flutter applications. This package is ideal for applications that require voice commands, voice notes, or any other form of speech recognition.

### Features

*   Offline speech recognition
*   Real-time speech recognition
*   Supports multiple languages
*   Compatible with both Android and iOS platforms

### When to Use

*   Voice assistants
*   Voice-controlled applications
*   Speech-to-text applications
*   Voice notes and voice messaging

<-- END_DESCRIPTION -->

<-- START_TUTORIAL -->
# vosk_flutter_2 Tutorial
==========================

## Setup

To use the vosk_flutter_2 package, add the following dependency to your pubspec.yaml file:

```yml
dependencies:
  vosk_flutter_2: ^0.3.1
```

Then, run `flutter pub get` to install the package.

### Android Configuration

In your AndroidManifest.xml file, add the following permission:

```xml
<uses-permission android:name="android.permission.RECORD_AUDIO" />
```

### iOS Configuration

In your Info.plist file, add the following permission:

```xml
<key>NSMicrophoneUsageDescription</key>
<string>This app needs access to the microphone to work properly</string>
```

## Usage

To use the vosk_flutter_2 package, import it in your Dart file:

```dart
import 'package:vosk_flutter_2/vosk_flutter_2.dart';
```

Then, initialize the Vosk speech recognizer:

```dart
VoskFlutter2 vosk = VoskFlutter2();
await vosk.initVosk();
```

Start the speech recognition:

```dart
await vosk.startListening();
```

And handle the recognized text:

```dart
vosk.onResult((text) {
  print(text);
});
```

<-- END_TUTORIAL -->

<-- START_MAIN -->
```dart
import 'package:flutter/material.dart';
import 'package:vosk_flutter_2/vosk_flutter_2.dart';

void main() {
  runApp(MyApp());
}

class MyApp extends StatelessWidget {
  @override
  Widget build(BuildContext context) {
    return MaterialApp(
      title: 'Vosk Flutter Demo',
      theme: ThemeData(
        primarySwatch: Colors.blue,
      ),
      home: MyHomePage(),
    );
  }
}

class MyHomePage extends StatefulWidget {
  @override
  _MyHomePageState createState() => _MyHomePageState();
}

class _MyHomePageState extends State<MyHomePage> {
  VoskFlutter2 _vosk;
  String _recognizedText = '';

  @override
  void initState() {
    super.initState();
    _initVosk();
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(
        title: Text('Vosk Flutter Demo'),
      ),
      body: Center(
        child: Column(
          mainAxisAlignment: MainAxisAlignment.center,
          children: <Widget>[
            Text(
              _recognizedText,
              style: TextStyle(fontSize: 24),
            ),
            SizedBox(height: 20),
            ElevatedButton(
              onPressed: _startListening,
              child: Text('Start Listening'),
            ),
            SizedBox(height: 10),
            ElevatedButton(
              onPressed: _stopListening,
              child: Text('Stop Listening'),
            ),
          ],
        ),
      ),
    );
  }

  _initVosk() async {
    // Initialize the Vosk speech recognizer
    _vosk = VoskFlutter2();
    await _vosk.initVosk();
  }

  _startListening() async {
    // Start the speech recognition
    await _vosk.startListening();
    // Handle the recognized text
    _vosk.onResult((text) {
      setState(() {
        _recognizedText = text;
      });
    });
  }

  _stopListening() async {
    // Stop the speech recognition
    await _vosk.stopListening();
  }
}
```
// The application flow is as follows:
// 1. The user opens the app and is presented with a screen containing two buttons: "Start Listening" and "Stop Listening".
// 2. When the user presses the "Start Listening" button, the `_startListening` function is called, which starts the speech recognition using the `_vosk.startListening()` method.
// 3. As the user speaks, the recognized text is handled by the `_vosk.onResult()` method, which updates the `_recognizedText` variable with the recognized text.
// 4. The recognized text is then displayed on the screen.
// 5. When the user presses the "Stop Listening" button, the `_stopListening` function is called, which stops the speech recognition using the `_vosk.stopListening()` method.

<-- END_MAIN -->